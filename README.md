<h1>Discrepancies Between Subjective and Objective Evaluations of NYC School Performance</h1>
By: Michelle Choi, Yichen Guan, and Samantha Udolf

<h2> Overview and Motivation </h2>
Though the Department of Education (DOE) is responsible for providing funding and overseeing regulation for all New York City public schools, the resulting performance of these academic institutions varies widely across the city. Unfortunately, these trends are not entirely unexpected given that the DOE has only limited resources that it must allocate amongst its crowded school district. Since access to education is absolutely essential in improving quality of life, our motivation for this project was to investigate which factors contributed most to an enhanced educational experience. In particular, since policymakers and government officials have the most influence over resource allocation amongst and within such schools, we sought to analyze school performance in a manner that would inform these stakeholders how to shape educational reform to affect the most beneficial change. In other words, our goal was to analyze different factors hypothesized to contribute to enhanced education quality to isolate which variables were most strongly correlated with positive results. This analysis is critical because, equipped with this information, educational policymakers would have a better understanding of how to allocate their limited resources by prioritizing reforms that are most strongly correlated with improved performance. Motivated by this goal, our project aims to produce an interactive tool that would allow users to toggle different factors influencing educational outcomes to estimate the success of policies aimed to reform particular parts of the school system.

From our initial research, we quickly found that factors such as class size and program funding have consistently been found to improve school performance. While we found strong arguments demonstrating the correlation between such variables with school performance, we felt that existing knowledge could be improved by a better understanding of a comparative analysis between such factors. In other words, our project seeks to find the relative effect of each factor’s contribution to educational success compared to other major influences. Moreover, we wanted to investigate whether other variables that have been subject to far less scrutiny, such as surrounding crime rates or age of school (i.e. duration of existence), play just as large of a role in educational performance as more well-researched variables do.

Finally, in discussing how to evaluate school performance, we realized that schools receive both objective and subjective feedback and that it is difficult to determine whether such results align. Hence we decided to whether various factors influence both objective (i.e. test scores) and subjective (i.e. survey taken by teachers or parents about school performance) results, and in turn study whether the results for both types of evaluations are similar.

<h2> Related Work </h2>
Our motivation for this project stemmed from the unanimous sentiment amongst our group members that existing problems in the education system had persisted for far too long without proper reform. In particular, the 2010 film Waiting for “Superman” struck our attention since it revealed astonishing inefficiencies in the United States’ Department of Education that we felt required immediate attention. In fact, the film’s emphasis on the rampant inequality and poor teacher incentive structures helped us realize that many of the system’s flaws could be easily addressed through more informed policy decisions. As a result, we felt inspired to utilize the skills we developed during CS109 to perform a deeper analysis on an issue we felt warranted more thorough investigation given its long-term implications for the wellbeing and productivity of the country’s youth.

While searching for data on this subject matter, we came across a project (http://itisaasta.com/nycs/) designed for a CS171 assignment that helped guide our approach to the problem. The project’s citations included a list of references that guided us to the New York City Open Data website (https://data.cityofnewyork.us/), which we used as a starting point to gather our datasets. Though we used some of the data from this source to find math scores for various schools, we did independent research to find sources for data regarding demographic, safety, and funding information for NYC schools. Moreover, we used the NYC Open Data source to find our data for other variables but did not use the same datasets as the CS171 project did; this is because our project was analyzed 2011-2012 (the only year where we could find data for our our variables of interest) instead of the 2010-2011 data the CS171 project used, and we needed data for each school rather than for districts or bureau levels. Finally, though the CS171 project’s focus on education aligned with our general interest, we approached the problem slightly differently in that we aimed to inform policy makers where to invest to improve school outcomes while the CS171 project targeted parents looking for schools for their children as stakeholders. In summary, while the CS171 project helped guide our approach towards considering potential variables and finding data, we did not use it to inform our analysis because the CS171 project only visualized existing trends while ours had a more analytical purpose of identifying factors that could improve school performance.

<h2> Initial Questions and Project Focus Development </h2>
Based on accessible data, we decided to investigate seven independent variables including school type (i.e. charter vs. public), class size, demographic breakdown (i.e. race and gender), school safety (i.e. crime rates in surrounding areas) and funding. The dependent variables included math test scores and survey data (i.e. evaluations of school performances by teachers, students, and parents). Given these variables, our initial goal was to answer the following questions:

* How do the different independent variables interact (ex. what is the interaction between funding and class size)?

* Do the independent variables have a different correlation with the subjective and objective dependent variables? In other words, do high test scores correspond with positive survey results in the same schools?

* Which independent variables have the largest effect on each of the dependent variables? How should policymakers prioritize reforms aimed at influencing each of these independent variables?

After deciding to compare different types of regression models and predictive analysis in our final report, we also decided to investigate the following questions:

* Which regression model best fits our data? In other words, which regression model has the lowest RMSE when trained on a sample data subset and then tested on the rest of the data?

* We noticed female percentages of students had a high positive coefficient with math score results. Why did we notice this effect?

<h2> Structure of the Project </h2>
The code for our project is contained within two separate folders, one titled Data Analysis and one titled Interactive Tool. The Data Analysis folder contains all of the code related to data scraping, cleaning, and analysis. Meanwhile, the Interactive Tool folder contains all of the code used to develop a webpage where users could manipulate variables to see what our linear regression model would predict the resulting math and survey scores would be.

<h3> Data Analysis </h3>
The Data Analysis folder contains 4 ipython notebooks that should be opened in the following order. First, MergeFiles.ipynb contains all of the code that cleans data imported from CSV’s downloaded straight from websites (all of our sources are listed at the bottom of this README. Second, MergeFiles references GetFunding.ipynb, which scrapes data regarding funding information for each school. These two files represent the two parts of our data collection process. Third, Predictions_Inference_Visualizations.ipynb contains our exploratory analysis and our final analysis. Hence it contains the regression models we tested, initial visualizations and analysis, and a conclusions we drew from our models to answer all of our initial questions. Finally, Visualizations_for_the_Web.ipynb contains a few more visualizations that we created specifically for our website.


<h3> Interactive Tool Folder</h3>
Within the Interactive Tool folder, index.html contains the code used to create the tool. It links to 2 important scripts that are hosted within the js file of the folder. First, it links to js/colResizable-1.5.min.js, which contains the code to generate the multipoint slider used for the demographic analysis. This code was adapted from http://www.bacubacu.com/colresizable/#samples. The script for this code is written within the header, starting on line 25. Second, it links to a js file called js/my_first_tour.js, which also relies on code from js/hopscotch.js to generate the informational tour upon opening the page. Code for these files was adapted from https://github.com/linkedin/hopscotch, modified to create a tour that matched the needs of our page.The next portion of the code contains CSS elements that were used to layout the page and create the blackboard background. Other css elements and images specific to hopscotch and the slider were include in the css, stylesheets, and img folders included in the Interactive Tool Folder. After setting up these CSS elements, we created the html elements for all of the sliders and outputs. At the start of the script thereafter, we initialized variables globally so we did not have to run update functions for every variable each time any variable was changed. Then we loaded in json files that we outputted from the regressions we ran in the data analysis section, which were in the form of dictionaries keyed by variable type with values as the coefficient number. Then we created d3 selectors and html elements that would run various update functions when the user changed a variable. An update function existed for each variable, such that each time a variable was changed its global variable value would be altered and then an update_score() function would be called. This update score function would run 2 equations, each of which used the coefficients loaded in from the regressions of either the survey or math data, and output a predicted score based on the linear model created using our regression coefficients.Next, two interactive visualizations were created in the update_demogvis() and update_gendervis() functions, which each would be called when the appropriate sliders were changed. These functions took the updated percentage breakdowns as inputs, and would generate pie visualizations matching these percentages. Finally, each visualization used “mouse on” and “mouse out” events to create an effect where corresponding pie elements would be highlighted if their legend element was highlighted. This process was executed by attributing identical id’s to corresponding legend and pie elements, such that when an element was moused over, all other elements within that visualization would greatly decrease in opacity such that only the element of interest remained. 

Finally, we had problems creating a github page within our project repository that could then be converted into a publicly accessible github page. Hence we created a github page on a separate repository that we used to generate the github page:	https://github.com/mchoi4194/mchoi4194.github.ioTo keep all of our code in a centralized location, we simply copied the exact final code from that repository into the Interactive Tool folder within our project repository even though the repository that is actually connected to the http://mchoi4194.github.io/ page is the one listed above. In other words, the code within our project repository is exactly the same as the one used to generate the interactive tool, it just is not actually the repository connected to the generated page.

<h2> Sources </h2>
Downloaded and Cleaned:
* Charter School Math Scores: https://data.cityofnewyork.us/Education/Math-Test-Results-2006-2012-Charter-Schools/43qc-8vv8
* Public School Math Scores: https://data.cityofnewyork.us/Education/Math-Test-Results-2006-2012-School-All-Students/3mrr-8h5c
* Class Size: https://data.cityofnewyork.us/Education/2010-2011-Class-Size-School-level-detail/urz7-pzb3 
* Demographic:http://schools.nyc.gov/Accountability/data/default.htm (Demographic Snapshots link).
* Survey data: https://data.cityofnewyork.us/Education/NYC-School-Survey-2011/mnz3-dyi8 
* Safety data: https://data.cityofnewyork.us/Education/School-Safety-Report/qybk-bjjc 

Scraping:

* Funding: http://schools.nyc.gov/AboutUs/funding/schoolbudgets/default.htm
