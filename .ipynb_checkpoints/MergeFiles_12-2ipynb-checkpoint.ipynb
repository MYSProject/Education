{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File Math.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9c3bb48d37ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import all data sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Math.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mCharter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Math-Charter.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ClassSize.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mSurvey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SurveyData.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Choi/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    472\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Choi/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Choi/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Choi/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Choi/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3173)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:5912)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File Math.csv does not exist"
     ]
    }
   ],
   "source": [
    "#import all data sets\n",
    "Math=pd.read_csv(\"data/Math.csv\")\n",
    "Charter = pd.read_csv(\"data/Math-Charter.csv\")\n",
    "Size = pd.read_csv(\"daClassSize.csv\")\n",
    "Survey = pd.read_csv(\"SurveyData.csv\")\n",
    "Demo = pd.read_csv(\"DemographicData.csv\")\n",
    "funding = pd.read_csv(\"fundingdf_new.csv\")\n",
    "Safety = pd.read_csv(\"School_Safety_Report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CLEAN UP CHARTER DATA\n",
    "#drop irrelevant demographic info and years\n",
    "Charter = Charter[Charter[\"Year\"] == 2011]\n",
    "Charterdf = Charter.drop(\"Demographic\", axis = 1)\n",
    "#set school type to charter because schools in charter.csv were only from charter schools\n",
    "Charterdf[\"School Type\"] = \"Charter\"\n",
    "Charterdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CLEAN UP MATH DATA\n",
    "#drop irrelevant demographic info and years\n",
    "Mathdf = Math.drop(\"Demographic\", axis = 1)\n",
    "Mathdf =  Mathdf[Mathdf[\"Year\"] == 2011]\n",
    "#set school type to public because schools in the math.csv were only from public schools\n",
    "Mathdf[\"School Type\"] = \"Public\"\n",
    "Mathdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge math data and charter data\n",
    "merge1 = Mathdf.append(Charterdf, ignore_index=True)\n",
    "merge1.rename(columns={'Mean Scale Score':'Mean_Scale_Score'}, inplace=True)\n",
    "# convert meanscalescores into ints\n",
    "counter = 0\n",
    "for i in merge1.iterrows():\n",
    "    if i[1][\"Mean_Scale_Score\"] == \"s\":\n",
    "        merge1.ix[counter, \"Mean_Scale_Score\"] = \"NaN\"\n",
    "    else:\n",
    "        merge1.ix[counter, \"Mean_Scale_Score\"]= int(i[1][\"Mean_Scale_Score\"])\n",
    "    counter += 1\n",
    "type(merge1.iloc[0][\"Mean_Scale_Score\"])\n",
    "merge1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CLEAN UP SIZE DATA\n",
    "#Standardize DBN numbers for class size data\n",
    "Size[\"DBN\"] = \"N/A\"\n",
    "counter = 0\n",
    "for i in Size.iterrows():\n",
    "    #concatenate school district and code to form dbn numbers\n",
    "    newdbn = \"0\"+str(i[1][\"CSD\"])+i[1][\"SCHOOL CODE\"]\n",
    "    Size.ix[counter, \"DBN\"]= newdbn\n",
    "    #take only sencond number of grades with a 0 added to the beginning\n",
    "    if type(i[1][\"GRADE \"]) == float:\n",
    "        grade = \"N/A\"\n",
    "    elif len(i[1][\"GRADE \"]) == 2:\n",
    "        grade = i[1][\"GRADE \"][1:]\n",
    "    Size.ix[counter, \"GRADE \"] = grade\n",
    "    if math.isnan((i[1][\"AVERAGE CLASS SIZE\"])):\n",
    "        continue\n",
    "    else:\n",
    "        Size.ix[counter, \"AVERAGE CLASS SIZE\"] = float(i[1][\"AVERAGE CLASS SIZE\"])\n",
    "    counter += 1\n",
    "\n",
    "#Only keep relevant class size columns\n",
    "sizeallcolumns = Size.columns \n",
    "sizedropcolumns = []\n",
    "# print len(sizeallcolumns)\n",
    "for title in sizeallcolumns:\n",
    "    if title in [\"SCHOOL NAME\", \"BOROUGH\", \"GRADE \", 'PROGRAM TYPE', \"AVERAGE CLASS SIZE\", \"DBN\"]:\n",
    "        continue\n",
    "    else:\n",
    "        sizedropcolumns.append(title)\n",
    "\n",
    "#Keep only gen ed samples to standardize classroom type we gather data from\n",
    "Sizedf = Size.drop(sizedropcolumns, axis = 1)\n",
    "Sizedf =  Sizedf[Sizedf[\"PROGRAM TYPE\"] == \"GEN ED\"]\n",
    "\n",
    "#Modify format of column names so they match others while merging\n",
    "Sizedf.columns = ['School Name', 'Borough', 'Grade', 'Program Type', 'Average Class Size', 'DBN']\n",
    "Sizedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge class size data into other merged data\n",
    "merge2 = merge1.merge(Sizedf, on = [\"DBN\", \"Grade\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean up years for demographic data\n",
    "Demog =  Demo[Demo[\"Year\"] == \"2010-11\"]\n",
    "\n",
    "#Only keep relevant demographic columns\n",
    "demogallcolumns = Demog.columns \n",
    "demogdropcolumns = []\n",
    "for title in demogallcolumns:\n",
    "    if title in [\"DBN\", \"School Name\", \"% Female\", \"% Male\", \"% Asian\", \"% Black\", \"% Hispanic\", \"% Other\", \"% White\"]:\n",
    "        continue\n",
    "    else:\n",
    "        demogdropcolumns.append(title)\n",
    "\n",
    "#drop irrelvant columns\n",
    "Demogdf = Demog.drop(demogdropcolumns, axis = 1)\n",
    "\n",
    "#convert percentages into floats without percent sign\n",
    "for i in xrange(0, len(Demogdf[\"DBN\"])):\n",
    "    Demogdf.iloc[i][\"% Female\"] = float(Demogdf.iloc[i][\"% Female\"][:-1])/100\n",
    "    Demogdf.iloc[i][\"% Male\"] = float(Demogdf.iloc[i][\"% Male\"][:-1])/100\n",
    "    Demogdf.iloc[i][\"% Asian\"] = float(Demogdf.iloc[i][\"% Asian\"][:-1])/100\n",
    "    Demogdf.iloc[i][\"% Black\"] = float(Demogdf.iloc[i][\"% Black\"][:-1])/100\n",
    "    Demogdf.iloc[i][\"% Hispanic\"] = float(Demogdf.iloc[i][\"% Hispanic\"][:-1])/100\n",
    "    Demogdf.iloc[i][\"% Other\"] = float(Demogdf.iloc[i][\"% Other\"][:-1])/100\n",
    "    Demogdf.iloc[i][\"% White\"] = float(Demogdf.iloc[i][\"% White\"][:-1])/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge demographic data with other merged data\n",
    "merge3 = merge2.merge(Demogdf, on = \"DBN\", how = \"left\")\n",
    "merge3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean safety data\n",
    "#keep only relevant columns\n",
    "safetyallcolumns = Safety.columns \n",
    "safetydropcolumns = []\n",
    "for title in safetyallcolumns:\n",
    "    if title in [\"DBN\", \"AvgOfMajor N\", \"AvgOfVio N\", \"AvgOfNoCrim N\"]:\n",
    "        continue\n",
    "    else:\n",
    "        safetydropcolumns.append(title)\n",
    "Safetydf = Safety.drop(safetydropcolumns, axis = 1)\n",
    "Safetydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge safety data with other data\n",
    "merge4 = merge3.merge(Safetydf, on = \"DBN\", how = \"left\")\n",
    "merge4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CLEAN UP SURVEY DATA\n",
    "# SurveyWhole = Survey.append(Survey75, ignore_index=True)\n",
    "allcolumns = Survey.columns \n",
    "dropcolumns = []\n",
    "for title in allcolumns:\n",
    "    #create array of columns to drop in dropcolumns array\n",
    "    if title in [\"dbn\", \"schoolname\", \"eng_p_11\", \"eng_s_11\", \"eng_t_11\", \"aca_p_11\", \"aca_t_11\", \"aca_s_11\"]:\n",
    "        continue   \n",
    "    else:\n",
    "        dropcolumns.append(title)\n",
    "#drop irrelevant columns and edit column format so they can merge\n",
    "Surveydf = Survey.drop(dropcolumns, axis = 1)\n",
    "Surveydf.rename(columns={'dbn':'DBN'}, inplace=True)\n",
    "Surveydf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merge5 = merge4.merge(Surveydf, on = \"DBN\", how = \"left\")\n",
    "merge5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean up funding columns\n",
    "funding.columns = [\"DBN\", \"Funding\"]\n",
    "funding.head()\n",
    "# for i in funding.iterrows():\n",
    "#     print i[1]\n",
    "#     funding = funding.replace(\"$\", \"\")\n",
    "#     funding = funding.replace(\",\", \"\")\n",
    "# type(mergedf.funding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mergedf = merge5.merge(funding, on = \"DBN\", how = \"left\")\n",
    "mergedf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = []\n",
    "for i in mergedf.iterrows():\n",
    "    if i[1][\"Mean_Scale_Score\"] != \"NaN\":\n",
    "        array.append(i[1][\"Mean_Scale_Score\"])\n",
    "counter = 0\n",
    "for i in mergedf.iterrows():\n",
    "    if i[1][\"Mean_Scale_Score\"] == \"NaN\":\n",
    "#         print \"hi\"\n",
    "        mergedf.ix[counter, \"Mean_Scale_Score\"] = np.mean(array)\n",
    "    counter +=1\n",
    "        \n",
    "array_size = []\n",
    "for i in mergedf.iterrows():\n",
    "    if ~np.isnan(i[1][\"Average Class Size\"]):\n",
    "#         print i\n",
    "#         break\n",
    "        array_size.append(i[1][\"Average Class Size\"])\n",
    "# print array_size\n",
    "counter1 = 0\n",
    "for i in mergedf.iterrows():\n",
    "#     if i[1][\"Average Class Size\"] == \"NaN\"or i[1][\"Average Class Size\"] == \"nan\":\n",
    "    if np.isnan(i[1][\"Average Class Size\"]):\n",
    "#         print \"hi\"\n",
    "        mergedf.ix[counter1, \"Average Class Size\"] = np.mean(array_size)\n",
    "    counter1 +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array_female = []\n",
    "counter2 = 0\n",
    "for i in mergedf.iterrows():\n",
    "    if ~np.isnan(i[1][\"% Female\"]):\n",
    "        array_female.append(i[1][\"% Female\"])\n",
    "print np.mean(array_female)\n",
    "for i in mergedf.iterrows():\n",
    "    if np.isnan(i[1][\"% Female\"]):\n",
    "        mergedf.ix[counter2, \"% Female\"] = np.mean(array_female)\n",
    "    counter2 +=1\n",
    "array_asian = []\n",
    "counter3 = 0\n",
    "for i in mergedf.iterrows():\n",
    "    if ~np.isnan(i[1][\"% Asian\"]):\n",
    "#         print \"hi\"\n",
    "        array_asian.append(i[1][\"% Asian\"])\n",
    "for i in mergedf.iterrows():\n",
    "    if np.isnan(i[1][\"% Asian\"]):\n",
    "        mergedf.ix[counter3, \"% Asian\"] = np.mean(array_asian)\n",
    "    counter3 +=1\n",
    "array_black = []\n",
    "counter4 = 0\n",
    "for i in mergedf.iterrows():\n",
    "    if ~np.isnan(i[1][\"% Black\"]):\n",
    "#         print \"hi\"\n",
    "        array_black.append(i[1][\"% Black\"])\n",
    "# print np.mean(array_black)\n",
    "for i in mergedf.iterrows():\n",
    "    if np.isnan(i[1][\"% Black\"]):\n",
    "        mergedf.ix[counter4, \"% Black\"] = np.mean(array_black)\n",
    "    counter4 +=1\n",
    "array_his = []\n",
    "counter5 = 0\n",
    "for i in mergedf.iterrows():\n",
    "    if ~np.isnan(i[1][\"% Hispanic\"]):\n",
    "#         print \"hi\"\n",
    "        array_his.append(i[1][\"% Hispanic\"])\n",
    "print np.mean(array_his)\n",
    "for i in mergedf.iterrows():\n",
    "    if np.isnan(i[1][\"% Hispanic\"]):\n",
    "        mergedf.ix[counter5, \"% Hispanic\"] = np.mean(array_his)\n",
    "    counter5 +=1\n",
    "array_crime = []\n",
    "counter6 = 0\n",
    "for i in mergedf.iterrows():\n",
    "    if ~np.isnan(i[1][\"AvgOfNoCrim N\"]):\n",
    "#         print \"hi\"\n",
    "        array_crime.append(i[1][\"AvgOfNoCrim N\"])\n",
    "print np.mean(array_crime)\n",
    "for i in mergedf.iterrows():\n",
    "    if np.isnan(i[1][\"AvgOfNoCrim N\"]):\n",
    "        mergedf.ix[counter6, \"AvgOfNoCrim N\"] = np.mean(array_crime)\n",
    "    counter6 +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print array_size\n",
    "# for i in mergedf.iterrows():\n",
    "#     if i[1][\"Mean_Scale_Score\"] == \"NaN\":\n",
    "#         print \"hi\"\n",
    "# print np.mean(array)\n",
    "counter2 = 0\n",
    "for i in mergedf.iterrows():\n",
    "    mergedf.ix[counter2, \"Funding\"] = int(i[1][\"Funding\"])\n",
    "    counter += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mergedf.columns = ['DBN', 'Grade', 'Year', 'Number_Tested', 'Mean_Scale_Score', 'Num_Level1', 'Pct_Level1', 'Num_Level2', 'Pct_Level2', 'Num_Level3', 'Pct_Level3', 'Num_Level4', 'Pct_Level4', 'Num_Level3_and4', 'Pct_Level3_and4', 'School_Type', 'School_Name_x', 'Borough', 'Program_Type', 'Average_Class_Size', 'School_Name_y', 'Female_Percentage', 'Male_Percentage', 'Asian_Percentage', 'Black_Percentage', 'Hispanic_Percentage', 'Other_Percentage', 'White_Percentage', 'Avg_Major_N', 'Avg_No_Crim_N', 'Avg_Vio_N', 'School_Name', 'Eng_p_11', 'Aca_p_11', 'Eng_t_11', 'Aca_t_11', 'Eng_s_11', 'Aca_s_11', 'Funding']\n",
    "print mergedf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mergedf.to_csv(\"mergedfupdate_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in mergedf[\"Avg_No_Crim_N\"]:\n",
    "    if i == \"NaN\":\n",
    "        print \"Hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
